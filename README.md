# American-Sign-Language

American Sign Language (ASL) is a complete, natural language that has the same linguistic properties as spoken languages, with grammar that differs from English. ASL is expressed by movements of the hands and face. It is the primary language of many North Americans who are deaf and hard of hearing, and is used by many hearing people as well.

![alt text](https://www.nidcd.nih.gov/sites/default/files/Content%20Images/NIDCD-ASL-hands-2014.jpg)


*Note-* As sign language will be standardised across the coountry, this project would help learn and understand this language.

## Dataset
*Link-* https://www.kaggle.com/grassknoted/asl-alphabet

The training data set contains 87,000 images which are 200x200 pixels. There are 29 classes, of which 26 are for the letters A-Z and 3 classes for SPACE, DELETE and NOTHING.
These 3 classes are very helpful in real time applications, and classification.
The test data set contains a mere 29 images, to encourage the use of real world test images.

## Training
Dataset was trained on Pretrained Model VGG16 for 10 epochs using a batch size of 64. Model was trained on 80% of the dataset and rest was provided as validation data.

## Results
*Visit-* https://github.com/Rajatjain97/American-Sign-Language/tree/master/Testing%20Data%20Result

## Conclusion
This application having real potential in improving the lives of the hearing-impaired and as such it would be a worthy goal to continue development.

